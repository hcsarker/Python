{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3bd8aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77daa59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rows after cleaning: 6941\n"
     ]
    }
   ],
   "source": [
    "# 1ï¸âƒ£ Load Dataset\n",
    "# Read only the needed columns and handle missing values encoded as -200\n",
    "cols = ['CO(GT)', 'C6H6(GT)', 'NOx(GT)', 'NO2(GT)', 'T']\n",
    "data = pd.read_csv(\"../content/AirQualityUCI.csv\", sep=';', decimal=',', usecols=lambda c: c in cols)\n",
    "# Replace sensor missing-value code -200 with NaN, then drop rows missing in our columns\n",
    "data = data.replace(-200, np.nan).dropna(subset=cols)\n",
    "print(f\"Loaded rows after cleaning: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ecb2fde9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.6</td>\n",
       "      <td>11.9</td>\n",
       "      <td>166.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>103.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>13.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.2</td>\n",
       "      <td>9.2</td>\n",
       "      <td>172.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.6</td>\n",
       "      <td>6.5</td>\n",
       "      <td>131.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>89.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>62.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>62.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>45.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CO(GT)  C6H6(GT)  NOx(GT)  NO2(GT)     T\n",
       "0      2.6      11.9    166.0    113.0  13.6\n",
       "1      2.0       9.4    103.0     92.0  13.3\n",
       "2      2.2       9.0    131.0    114.0  11.9\n",
       "3      2.2       9.2    172.0    122.0  11.0\n",
       "4      1.6       6.5    131.0    116.0  11.2\n",
       "5      1.2       4.7     89.0     96.0  11.2\n",
       "6      1.2       3.6     62.0     77.0  11.3\n",
       "7      1.0       3.3     62.0     76.0  10.7\n",
       "8      0.9       2.3     45.0     60.0  10.7\n",
       "11     0.7       1.1     16.0     28.0  11.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53283c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6941, 4) (6941,)\n"
     ]
    }
   ],
   "source": [
    "# 2ï¸âƒ£ Select Features and Target\n",
    "features = ['CO(GT)', 'C6H6(GT)', 'NOx(GT)', 'NO2(GT)']\n",
    "X = data[features].values\n",
    "y = data['T'].values  # Temperature as example target\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dbc37be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3ï¸âƒ£ Split Dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "423cb501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4ï¸âƒ£ Scale Features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed88ae32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hridoy/venv/lib/python3.13/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 5ï¸âƒ£ Build Model\n",
    "model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(4,)),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1)  # predicting continuous value\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a31111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6ï¸âƒ£ Compile\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc3bcbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 351.8200 - mae: 16.5147 - val_loss: 293.9779 - val_mae: 14.6207\n",
      "Epoch 2/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 192.8785 - mae: 11.1615 - val_loss: 123.7036 - val_mae: 8.9089\n",
      "Epoch 3/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 104.2722 - mae: 8.0847 - val_loss: 82.0335 - val_mae: 7.2169\n",
      "Epoch 4/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 69.2185 - mae: 6.5908 - val_loss: 56.2070 - val_mae: 5.9606\n",
      "Epoch 5/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 51.9140 - mae: 5.7218 - val_loss: 45.8919 - val_mae: 5.3939\n",
      "Epoch 6/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 44.8541 - mae: 5.2933 - val_loss: 41.3940 - val_mae: 5.1241\n",
      "Epoch 7/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 41.3781 - mae: 5.0527 - val_loss: 38.9494 - val_mae: 4.9550\n",
      "Epoch 8/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 39.1717 - mae: 4.9197 - val_loss: 37.3297 - val_mae: 4.8603\n",
      "Epoch 9/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37.6536 - mae: 4.8089 - val_loss: 36.0865 - val_mae: 4.7649\n",
      "Epoch 10/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 36.5109 - mae: 4.7297 - val_loss: 35.2147 - val_mae: 4.7093\n",
      "Epoch 11/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35.8362 - mae: 4.6927 - val_loss: 34.2982 - val_mae: 4.6655\n",
      "Epoch 12/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 35.1190 - mae: 4.6389 - val_loss: 33.8180 - val_mae: 4.6332\n",
      "Epoch 13/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 34.6443 - mae: 4.6093 - val_loss: 33.4370 - val_mae: 4.5997\n",
      "Epoch 14/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34.2590 - mae: 4.5766 - val_loss: 32.9631 - val_mae: 4.5725\n",
      "Epoch 15/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33.8770 - mae: 4.5520 - val_loss: 33.1163 - val_mae: 4.5551\n",
      "Epoch 16/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33.5521 - mae: 4.5249 - val_loss: 32.1708 - val_mae: 4.5457\n",
      "Epoch 17/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33.3349 - mae: 4.5150 - val_loss: 31.9701 - val_mae: 4.5142\n",
      "Epoch 18/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33.0235 - mae: 4.4942 - val_loss: 32.8768 - val_mae: 4.5095\n",
      "Epoch 19/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32.8610 - mae: 4.4786 - val_loss: 31.7517 - val_mae: 4.4774\n",
      "Epoch 20/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32.5118 - mae: 4.4583 - val_loss: 31.3522 - val_mae: 4.4620\n",
      "Epoch 21/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32.3676 - mae: 4.4476 - val_loss: 31.2477 - val_mae: 4.4434\n",
      "Epoch 22/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32.1667 - mae: 4.4281 - val_loss: 31.0828 - val_mae: 4.4354\n",
      "Epoch 23/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31.9399 - mae: 4.4214 - val_loss: 31.1205 - val_mae: 4.4155\n",
      "Epoch 24/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31.7970 - mae: 4.4045 - val_loss: 30.7088 - val_mae: 4.4058\n",
      "Epoch 25/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 31.5627 - mae: 4.3863 - val_loss: 30.4659 - val_mae: 4.3984\n",
      "Epoch 26/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 31.3803 - mae: 4.3726 - val_loss: 30.4713 - val_mae: 4.3841\n",
      "Epoch 27/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31.1877 - mae: 4.3658 - val_loss: 30.7253 - val_mae: 4.3678\n",
      "Epoch 28/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 31.0457 - mae: 4.3550 - val_loss: 30.1730 - val_mae: 4.3701\n",
      "Epoch 29/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30.9136 - mae: 4.3381 - val_loss: 29.8048 - val_mae: 4.3567\n",
      "Epoch 30/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30.7604 - mae: 4.3299 - val_loss: 29.7784 - val_mae: 4.3380\n",
      "Epoch 31/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30.5505 - mae: 4.3211 - val_loss: 29.7506 - val_mae: 4.3213\n",
      "Epoch 32/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30.4217 - mae: 4.3028 - val_loss: 29.5326 - val_mae: 4.3128\n",
      "Epoch 33/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30.3211 - mae: 4.2974 - val_loss: 29.7159 - val_mae: 4.3212\n",
      "Epoch 34/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30.1510 - mae: 4.2901 - val_loss: 29.3477 - val_mae: 4.3013\n",
      "Epoch 35/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30.0341 - mae: 4.2828 - val_loss: 29.1817 - val_mae: 4.2832\n",
      "Epoch 36/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 29.8463 - mae: 4.2666 - val_loss: 30.5012 - val_mae: 4.3341\n",
      "Epoch 37/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.8760 - mae: 4.2627 - val_loss: 29.2975 - val_mae: 4.2730\n",
      "Epoch 38/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 29.7220 - mae: 4.2565 - val_loss: 29.4896 - val_mae: 4.2733\n",
      "Epoch 39/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 29.6318 - mae: 4.2515 - val_loss: 29.2396 - val_mae: 4.2662\n",
      "Epoch 40/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.6394 - mae: 4.2423 - val_loss: 29.1742 - val_mae: 4.2705\n",
      "Epoch 41/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.4880 - mae: 4.2369 - val_loss: 28.9206 - val_mae: 4.2540\n",
      "Epoch 42/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 29.4257 - mae: 4.2314 - val_loss: 28.8967 - val_mae: 4.2559\n",
      "Epoch 43/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.3403 - mae: 4.2284 - val_loss: 28.9052 - val_mae: 4.2420\n",
      "Epoch 44/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 29.3063 - mae: 4.2248 - val_loss: 29.0166 - val_mae: 4.2404\n",
      "Epoch 45/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.1388 - mae: 4.2105 - val_loss: 29.9555 - val_mae: 4.2791\n",
      "Epoch 46/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.1880 - mae: 4.2163 - val_loss: 28.9461 - val_mae: 4.2330\n",
      "Epoch 47/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 29.0853 - mae: 4.2083 - val_loss: 28.5508 - val_mae: 4.2283\n",
      "Epoch 48/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.0684 - mae: 4.2057 - val_loss: 28.7723 - val_mae: 4.2338\n",
      "Epoch 49/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.9993 - mae: 4.2070 - val_loss: 28.6963 - val_mae: 4.2224\n",
      "Epoch 50/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28.9416 - mae: 4.1983 - val_loss: 28.7635 - val_mae: 4.2234\n",
      "Epoch 51/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28.9023 - mae: 4.1959 - val_loss: 29.4156 - val_mae: 4.2396\n",
      "Epoch 52/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28.7726 - mae: 4.1899 - val_loss: 28.5487 - val_mae: 4.2272\n",
      "Epoch 53/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28.7359 - mae: 4.1819 - val_loss: 28.6375 - val_mae: 4.2142\n",
      "Epoch 54/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.7533 - mae: 4.1852 - val_loss: 28.2514 - val_mae: 4.2201\n",
      "Epoch 55/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.6577 - mae: 4.1771 - val_loss: 28.6114 - val_mae: 4.2190\n",
      "Epoch 56/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.6702 - mae: 4.1761 - val_loss: 29.1822 - val_mae: 4.2350\n",
      "Epoch 57/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28.5612 - mae: 4.1750 - val_loss: 28.7457 - val_mae: 4.2180\n",
      "Epoch 58/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28.5049 - mae: 4.1623 - val_loss: 28.1821 - val_mae: 4.2022\n",
      "Epoch 59/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28.4996 - mae: 4.1640 - val_loss: 28.9902 - val_mae: 4.2412\n",
      "Epoch 60/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28.4661 - mae: 4.1584 - val_loss: 28.2122 - val_mae: 4.2130\n",
      "Epoch 61/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28.4038 - mae: 4.1656 - val_loss: 28.7976 - val_mae: 4.2248\n",
      "Epoch 62/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28.3617 - mae: 4.1611 - val_loss: 28.6040 - val_mae: 4.2150\n",
      "Epoch 63/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.2989 - mae: 4.1502 - val_loss: 28.2735 - val_mae: 4.2029\n",
      "Stopped at epoch: 63\n"
     ]
    }
   ],
   "source": [
    "# 7ï¸âƒ£ Train\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"Stopped at epoch: {len(history.history['loss'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "581a7b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 27.7907 - mae: 4.1646\n",
      "âœ… Test MAE: 4.16\n"
     ]
    }
   ],
   "source": [
    "# 8ï¸âƒ£ Evaluate\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"âœ… Test MAE: {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37874f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "ğŸŒ¡ï¸ Predicted Temperature: 25.46 Â°C\n"
     ]
    }
   ],
   "source": [
    "# 9ï¸âƒ£ Predict\n",
    "sample = np.array([[2.5, 15, 90, 45]])  # Example gas levels\n",
    "sample_scaled = scaler.transform(sample)\n",
    "pred = model.predict(sample_scaled)\n",
    "print(f\"ğŸŒ¡ï¸ Predicted Temperature: {pred[0][0]:.2f} Â°C\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
